{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import linear_model, datasets, metrics\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## polyfit() function using sklearn.linear_model.RANSACRegressor ##\n",
    "\n",
    "The polyfit function takes a csv file with equal column sizes as input<br>\n",
    "Inputs:<ol>\n",
    "    <li>CSV file name,</li>\n",
    "    <li>polynomial order (to fit with), </li>\n",
    "    <li>maxdistance (the maximum deviation from the predicted line allowed for a data point to be considered an outlier)</li></ol>\n",
    "Returns:\n",
    "    the x and y columns of the fitted RANSAC line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polyfit(data, order, maxdistance, disable_linear = True):\n",
    "    #loading and extracting columns of data for x and y\n",
    "    df = pd.read_csv(data, header = None)\n",
    "    dfx = df[0].values\n",
    "    dfy = df[1].values\n",
    "    \n",
    "    #if variance of x is low, swap x and y, to prevent a vertical line\n",
    "    if np.var(dfx)<np.var(dfy):\n",
    "        tmp = dfx\n",
    "        dfx = dfy\n",
    "        dfy = tmp\n",
    "    \n",
    "    x = np.reshape(dfx, (len(dfx),1))\n",
    "    \n",
    "    y = np.reshape(dfy,(len(dfy),))\n",
    "    \n",
    "    #creation of the RANSACRegressor object\n",
    "    ransac = make_pipeline(PolynomialFeatures(order), linear_model.RANSACRegressor(residual_threshold = maxdistance))\n",
    "    \n",
    "    ransac.fit(x,y)\n",
    "    \n",
    "    #creation of boolean mask arrays to indicate the (x,y) pairs that are inliers vs. outliers\n",
    "    \n",
    "    \n",
    "    line_x = np.linspace(x.min(), x.max(), len(x))[:, np.newaxis]\n",
    "\n",
    "    line_y_ransac = ransac.predict(line_x)\n",
    "    \n",
    "    #additional linear fit\n",
    "    linear = linear_model.RANSACRegressor()\n",
    "    linear.fit(x,y)\n",
    "    \n",
    "    inlier_mask = linear.inlier_mask_\n",
    "    outlier_mask = np.logical_not(inlier_mask)\n",
    "    \n",
    "    line_y_linear = linear.predict(line_x)\n",
    "\n",
    "    lw = 2\n",
    "\n",
    "    plt.scatter(x,y, color=\"red\", marker = '.')\n",
    "\n",
    "    \n",
    "    #select best fitted line using mean squared error\n",
    "    \n",
    "    \n",
    "    MSE_regressor = metrics.mean_squared_error(dfy[:len(dfy)], line_y_ransac)\n",
    "    MSE_linear = metrics.mean_squared_error(dfy[:len(dfy)], line_y_linear)\n",
    "    \n",
    "    print(\"MSE of the linear fit: \"+str(MSE_linear))\n",
    "    print(\"MSE of the polynomial fit: \"+str(MSE_regressor))\n",
    "    \n",
    "    #determine the model to use based on lowest MSE\n",
    "    \n",
    "    chosen_model = None\n",
    "    alternative_model = None\n",
    "    if disable_linear == False:\n",
    "    \n",
    "        if (MSE_linear < MSE_regressor):\n",
    "            chosen_model = linear\n",
    "            alternative_model = ransac\n",
    "            print(\"Linear model chosen\")\n",
    "            \n",
    "            plot_line(line_x, line_y_linear, 'LinearRegressor',lw, color = \"cornflowerblue\")\n",
    "            \n",
    "        else:\n",
    "            chosen_model = ransac\n",
    "            alternative_model = linear\n",
    "            print(\"Polynomial model chosen\")\n",
    "            \n",
    "            plot_line(line_x, line_y_ransac, 'RANSACRegressor',lw, color = \"cornflowerblue\")\n",
    "\n",
    "    else:\n",
    "        chosen_model = ransac\n",
    "        alternative_model = linear\n",
    "        print(\"Polynomial model chosen\")\n",
    "        \n",
    "        plot_line(line_x, line_y_ransac, 'RANSACRegressor',lw, color = \"cornflowerblue\")\n",
    "    \n",
    "    #information to be returned x_coords, y_coords(linear prediction), y_coords(polynomial prediction), chosen sklearn model, unchosen sklearn model\n",
    "    cache = {\"x\":line_x, \"yl\":line_y_linear, \"yr\": line_y_ransac, \"model\": chosen_model, \"alt_model\": alternative_model}\n",
    "    \n",
    "    return cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_line(x,y, label, lw ,color = 'blue'):\n",
    "    plt.plot(x, y, color=color, linewidth=lw,\n",
    "    label=label)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.xlabel(\"Input\")\n",
    "    plt.ylabel(\"Response\")\n",
    "    \n",
    "    xmin,xmax = plt.xlim()\n",
    "    ymin,ymax = plt.ylim()\n",
    "    \n",
    "    if (xmax-xmin > ymax-ymin):\n",
    "        plt.ylim((ymax+ymin)/2-(xmax-xmin)/2,(ymax+ymin)/2+(xmax-xmin)/2)\n",
    "    else:\n",
    "        plt.xlim((xmax+xmin)/2-(ymax-ymin)/2,(xmax+xmin)/2+(ymax-ymin)/2)\n",
    "    print(plt.xlim())\n",
    "    print(plt.ylim())\n",
    "    \n",
    "    plt.axis(\"equal\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## arclength() <br>\n",
    "\n",
    "Takes input:\n",
    "<ol>\n",
    "    output cache of polyfit()\n",
    "    </ol><br>\n",
    "Returns:<br>\n",
    "<ol>\n",
    "    a cache containing the custom x coordinates, the y output of arclength as a function of each x coordinate, and the arclength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arclength(cache, linespace = 5000):\n",
    "    line_x = cache[\"x\"]\n",
    "    x_coords = np.linspace(line_x.min(),line_x.max(),linespace)[:, np.newaxis]\n",
    "    y_coords = cache[\"model\"].predict(x_coords)\n",
    "    \n",
    "    s_accumulative = 0.0\n",
    "    s_list = []\n",
    "    \n",
    "    \n",
    "    for i in range(len(x_coords)-1):\n",
    "        x_tmp = x_coords[i]\n",
    "        y_tmp = y_coords[i]\n",
    "        \n",
    "        x_next = x_coords[i+1]\n",
    "        y_next = y_coords[i+1]\n",
    "    \n",
    "        \n",
    "        s_accumulative += np.sqrt(np.power((x_next-x_tmp),2)+np.power((y_next-y_tmp),2)).item()\n",
    "        s_list.append(s_accumulative)\n",
    "    \n",
    "    return {\"x\": x_coords, \"s(x)\": s_list, \"arclength\":s_accumulative}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spacing() ##\n",
    "Inputs: <br>\n",
    " <ol> output from arclength(), the arclength between adjacent units (such as a particle in a microtubule) </ol><br>\n",
    "Outputs: <br>\n",
    " <ol> the respective x coordinates of the curve such that between each x coordinate, the change in arclength is constant. </ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacing(cache, step_size):\n",
    "    #based on the number of segments you want to divide the arc into, return the respective x coordinate at each segment\n",
    "    \n",
    "    l = np.arange(0,cache[\"arclength\"], float(step_size))[:, np.newaxis]\n",
    "    \n",
    "    s = np.asarray(cache[\"s(x)\"])\n",
    "    \n",
    "    x_locations = []\n",
    "    for val in l:\n",
    "        idx = np.abs(s-val).argmin()\n",
    "        x_locations.append(cache[\"x\"][idx])\n",
    "        \n",
    "    return x_locations\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## process_data() ##\n",
    "This is the only function you need to call to perform interpolation + evenly spaced particle picking along the interpolated line<br>\n",
    "Inputs:<br>\n",
    "<ol>\n",
    "    <li>directory - directory name(string) that contains csv files of the picked coordiantes</li>\n",
    "    <li>pixel_dist - distance along the arclength between adjacent units(this would be the spacing between two particles, for example)</li>\n",
    "    <li>disable_linear - set to True if only doing RANSAC regression, False if doing both linear and RANSAC regression and choosing the one with better fit</li>\n",
    "    <li>indexi - by default 0, the start position of the csv file you want to process</li>\n",
    "    <li>indexj - by default 10, the position of the last csv file you want to process</li>\n",
    "    <li>parse_whole_dataset - by default False, if set to True, indexi and indexj will be automatically set to 0 and the length of all the files in the directory as a list </li>\n",
    "</ol>\n",
    "<br>\n",
    "Outputs:<br>\n",
    "    <li>Does not return any value, instead, stores the interpolation graph and the coordiantes of adjacent units into two directories called test_data_plots and test_data_positions, respectively.(Make sure these directories are created in the current directory)</li>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(directory, pixel_dist ,disable_linear = True, indexi = 0, indexj = 10, parse_whole_dataset = False):\n",
    "    file_list = os.listdir(directory)\n",
    "    subset = [x for x in file_list if \".txt\" in x]\n",
    "    if (parse_whole_dataset == True):\n",
    "        indexi = 0\n",
    "        indexj = len(subset)\n",
    "    \n",
    "    for i in range(indexi,indexj):\n",
    "        poly_o = polyfit(directory+\"/\"+subset[i],2,1, disable_linear = disable_linear)\n",
    "        arclength_o = arclength(poly_o)\n",
    "        output = spacing(arclength_o, pixel_dist)\n",
    "        \n",
    "        plt.scatter(output, poly_o[\"model\"].predict(output))\n",
    "        plt.savefig(\"test_data_plots/\"+subset[i]+\"_plot.png\")    \n",
    "        plt.clf()\n",
    "        \n",
    "        unit_positions = pd.DataFrame({'x':output, 'y': poly_o[\"model\"].predict(output)})\n",
    "        unit_positions.to_csv(r\"test_data_positions/\"+subset[i]+\"_unit_pos.txt\", header = False, index = False)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.txt:\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'data.txt' does not exist: b'data.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-a25b645864ec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data.txt:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data.txt\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"x\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"y\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcache\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpolyfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data.txt\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdisable_linear\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zhe fan\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    683\u001b[0m         )\n\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zhe fan\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zhe fan\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zhe fan\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1135\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1136\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zhe fan\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1917\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'data.txt' does not exist: b'data.txt'"
     ]
    }
   ],
   "source": [
    "print(\"data.txt:\")\n",
    "print(pd.read_csv(\"data.txt\", index_col =  None, header = None).to_string(header = [\"x\",\"y\"], index = False))\n",
    "\n",
    "cache = polyfit(\"data.txt\",2,0.5,disable_linear = False)\n",
    "\n",
    "al = arclength(cache)\n",
    "print(\"arclength:\"+str(al[\"arclength\"]))\n",
    "#x_coordinates of evenly spaced segments\n",
    "output = spacing(al, 60.218)\n",
    "print(output)\n",
    "\n",
    "print(cache[\"model\"].predict(output))\n",
    "\n",
    "plt.scatter(output, cache[\"model\"].predict(output))\n",
    "\n",
    "pd.DataFrame({'x':output, 'y': cache[\"model\"].predict(output)})\n",
    "\n",
    "#plt.plot(x,y)\n",
    "\n",
    "#pd.DataFrame(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of the linear fit: 462.62261566604167\n",
      "MSE of the polynomial fit: 462.6094482747513\n",
      "Polynomial model chosen\n",
      "(1433.6017953345877, 3842.3026036654123)\n",
      "(1081.5602658345879, 3490.2610741654125)\n",
      "MSE of the linear fit: 130609.52634073097\n",
      "MSE of the polynomial fit: 130596.83720497937\n",
      "Polynomial model chosen\n",
      "(238.82980353458782, 2249.7424034654123)\n",
      "(3189.406785395921, 5200.319385326746)\n",
      "MSE of the linear fit: 346.09366164714504\n",
      "MSE of the polynomial fit: 348.68875653395855\n",
      "Linear model chosen\n",
      "(393.93255003458773, 1925.741766965412)\n",
      "(2732.220087651888, 4264.029304582712)\n",
      "MSE of the linear fit: 940.8097538217254\n",
      "MSE of the polynomial fit: 1009.3855516686568\n",
      "Linear model chosen\n",
      "(3679.6117817845875, 5074.288998215414)\n",
      "(1033.0218191105357, 2427.699035541362)\n",
      "MSE of the linear fit: 39160.36419921823\n",
      "MSE of the polynomial fit: 38106.330917857966\n",
      "Polynomial model chosen\n",
      "(3710.721330084588, 4574.824539915413)\n",
      "(27.48705808458749, 891.5902679154126)\n",
      "MSE of the linear fit: 64.60854446984271\n",
      "MSE of the polynomial fit: 90.77857858362653\n",
      "Linear model chosen\n",
      "(392.7098933345878, 976.8049516654122)\n",
      "(1346.1002445066063, 1930.1953028374307)\n",
      "MSE of the linear fit: 149125.48595669557\n",
      "MSE of the polynomial fit: 150762.25481415467\n",
      "Linear model chosen\n",
      "(2679.163243384588, 3828.979324615412)\n",
      "(2971.9333907274354, 4121.749471958259)\n",
      "MSE of the linear fit: 996.8560793401674\n",
      "MSE of the polynomial fit: 1009.8121116415954\n",
      "Linear model chosen\n",
      "(968.1679515845877, 1907.864448415412)\n",
      "(4394.252650209442, 5333.949147040266)\n",
      "MSE of the linear fit: 78.13925175921423\n",
      "MSE of the polynomial fit: 151.744839701356\n",
      "Linear model chosen\n",
      "(423.5741494845878, 3683.7857685154117)\n",
      "(481.3827076672885, 3741.594326698112)\n",
      "MSE of the linear fit: 16501.96525896571\n",
      "MSE of the polynomial fit: 16522.69863038605\n",
      "Linear model chosen\n",
      "(3955.355737184588, 5502.6489908154135)\n",
      "(1329.7947241291972, 2877.0879777600226)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "process_data(\"../test_data/test_data\", 60.218, disable_linear = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tip: if the variation of x is less than y axis, flip the axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
